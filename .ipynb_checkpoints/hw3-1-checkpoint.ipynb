{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26e973b9cd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYJUlEQVR4nO2da4zV5bXGn8WUWwFxmHEAuQgSVAoiyBSNc7SI1optlcbU1JjKaazUtE2ssclpej7UL00bY9vY5JSUWqO1VSstVWytCkiLVgOMdFQQRO4DjMwAw13u63xgew7qvM+azp7Ze9L3+SWTPbOfWf/97v/sZ/ZlvWstc3cIIf796VHuBQghSoPMLkQmyOxCZILMLkQmyOxCZMInSnljffr08QEDBnQ43sw6HHvixIkuO3ZFRQXVT548WVR8xPHjx5Najx78/3l0v6NszSc+wR9C7L5Ha4tuu5i1R7d96tSpovTo+MXAbvvQoUM4cuRImyemKLOb2fUAHgRQAeAhd/8x+/0BAwZg5syZST364/bs2ZOthca2trZSPTIcO8Fnn302jd27dy/VBw4cSPXovjU3Nye1Pn360Nhi/1Gdc845VGf3vV+/fjT22LFjVO/VqxfV2T/B6LYPHTpUlN63b1+qs8d69Dd5//33k9pf/vKXpNbhfz9mVgHgfwDMAPApALea2ac6ejwhRNdSzGuNqQDWu/tGdz8G4EkAN3XOsoQQnU0xZh8GoPGMn7cVrvsQZjbbzOrNrP7IkSNF3JwQohiKMXtbbyQ/9kbE3ee6e62710bvH4UQXUcxZt8GYMQZPw8HsKO45QghuopizL4CwFgzG21mvQB8BcCCzlmWEKKz6XDqzd1PmNm3AbyA06m3h919dRTH8o/Re/rDhw8ntegtQpS+GjRoENVZKiVKGUaplGgPwIoVK6h+7rnnJrUodTZx4kSqr1u3juoRbF/F/v37aWyULh0yZAjV9+3bl9SOHj1KY6PH01lnnUV1lh4DgJaWlqQ2duxYGstSiuxxXlSe3d2fA/BcMccQQpQGbZcVIhNkdiEyQWYXIhNkdiEyQWYXIhNkdiEyoaT17O5Oc4RR7pPBcs0AsHv3bqqzvCcADB48OKkNHTqUxkb54uXLl1P9oosuojor14zKQKPy2/79+1M9yuO/9957SS2qCa+qqqL6Jz/5Saqz47OyYCAu3T1w4ADVKysrqc4e61u2bKGxbK8K7R9AjyqE+LdBZhciE2R2ITJBZhciE2R2ITJBZhciE0qeemNlrFEah7UtjlJEO3bwvho1NTVUP3jwYFKLSlybmpqoPmzYx7p5fYjRo0dTnXXdfe2112hsdL8nT55M9ej4rHx3zJgxNDZ6PERdeVk6NfqbjR8/nupR6W+UNmQ+GDlyJI1lJc8s3ahndiEyQWYXIhNkdiEyQWYXIhNkdiEyQWYXIhNkdiEywaJ8Y2dSWVnpV199dVI/77zzaDzLdUftmCOi8lp2fNbiGojz6FEb623btlF93LhxSW3VqlU0Nsqzb9y4keq1tbVUZznhaBJqVGYa5bLZvoyoPPaf//wn1aOy49WreVd1Nvk3ejyxFtoLFizArl272uwnrWd2ITJBZhciE2R2ITJBZhciE2R2ITJBZhciE2R2ITKhpPXsPXr0oPnNtWvX0nhW/8xaPQPxiN3q6mqqz58/n+oMNjoYiMf7snp1gOdli81Vs7bFQJzHv/baa5PaP/7xDxp74YUXUj0a+cweE6zFNQDU1dVRPWolPX36dKqz/go7d+6ksaz9N+sBUJTZzWwzgAMATgI44e58h4UQomx0xjP71e6+qxOOI4ToQvSeXYhMKNbsDuBFM3vdzGa39QtmNtvM6s2snvXdEkJ0LcW+jK9z9x1mVgNgoZmtdfelZ/6Cu88FMBcAqqqqSld1I4T4EEU9s7v7jsJlM4A/AZjaGYsSQnQ+HTa7mfUzswEffA/gOgA8DyOEKBvFvIwfDOBPZvbBcR539+dZgJmhoqIiqY8YMYLeYGNjY1IbPnw4jd20aRPVo3p4lq8unIMk0R6AhoYGqkf1zWxcNat9BoA1a9ZQ/dixY1SPzjvrKx+d86imPOqnz2rxx44dS2OfffZZqkf7F6Jx1CzPP2rUKBrL+jqw2+2w2d19I4BLOhovhCgtSr0JkQkyuxCZILMLkQkyuxCZILMLkQklLXE9deoULeeMygZZCmvXLl6LE6W/5s2bR/W77rorqS1btozGXnzxxVSPUm9TpkyhOkvFvPrqqzQ2Oudf/OIXqR6lz1iL7qhF9m233Ub13r17U52V0P71r3+lsRMmTKB63759qR6tbf369UntmmuuobEdLbfWM7sQmSCzC5EJMrsQmSCzC5EJMrsQmSCzC5EJMrsQmVDSkc01NTV+yy23JPVojC4r9YxKOaP2vFG55MKFC5MaG78LAAMGDKD65ZdfTvXHH3+c6mw0cVSievz4capH5zW6b+z4rNwZAOrr66nOSnsB/neJWqRdd911VGetoIH4vLL9JtGx2d6GpUuXYu/evRrZLETOyOxCZILMLkQmyOxCZILMLkQmyOxCZILMLkQmlDTPPnDgQGejcFm+GACGDh2a1KKRzCNHjqT66tWrqT51anr+xS9+8QsaG+Xw2f1qT/zy5cuTWnS/o3xy1FL5lVdeoTrbQxCd8/Hjx1O9X79+VF+6dGlSu+yyy2hsc3Mz1S+44AKqr1u3juqMYcOGUX3Dhg1JbcmSJWhtbVWeXYickdmFyASZXYhMkNmFyASZXYhMkNmFyASZXYhMKGmevbq62lkf8srKShq/ZMmSpMby4ACwe/duqs+YMYPqjzzySFKL+nxHNeVRTfjKlSupztYe5XubmpqoHtVl19TUUH3r1q1J7fzzz6exW7ZsoXo0dnnv3r1JLeqdEOktLS1UZ7lwALjiiiuSWtRzno2yXrRoEfbs2dOxPLuZPWxmzWa26ozrBpnZQjN7t3DJXSqEKDvteRn/CIDrP3Ld9wAsdvexABYXfhZCdGNCs7v7UgB7PnL1TQAeLXz/KICZnbssIURn09EP6Aa7exMAFC6Tb9zMbLaZ1ZtZfdT3SwjRdXT5p/HuPtfda929tk+fPl19c0KIBB01+04zGwoAhUteIiSEKDsdNfsCALMK388C8EznLEcI0VWEeXYzewLANADVAHYC+AGApwE8BWAkgK0AvuzuH/0Q72NUVVX55z73uaS+ceNGGj9r1qyktmLFChobzWeP5nV//etfpzqD5Xvbo8+cOZPqbL775s2baWxUO33PPfdQPTovrEfB9u3baWxUrx6dt2nTpiW1qCd91B8h2vsQ1cu/++67SW348OE0trW1Nam9/PLLyb7xvFsEAHe/NSHxnSRCiG6FtssKkQkyuxCZILMLkQkyuxCZILMLkQklLXGtrKx0Vg4atVTu2bNnUmNjbAFg3759VD9w4ADVDx06lNSiNE11dTXV33nnHaqzMlGApySjFNOgQYOoHj0+ojTRokWLktp7771HY/v27Uv1qKyZleey0eEA8POf/5zqtbW1VI/aorOy52ee4dtWpk+fntTmz5+PlpYWtZIWImdkdiEyQWYXIhNkdiEyQWYXIhNkdiEyQWYXIhPCqrfOpEePHjR3atZmevD/OHjwYFLbtWsXjY1KOaM21nfffXdSe/rpp2nspk2bqD5q1Ciqs/0FADBnzpykFpVaRrnsaP9B1Gqa5cKjPPn8+fOpHrXoXrVqVVKLuiade+65VG9sbKT6lClTqP7qq68mtTvvvJPGPv/880nt6NGjSU3P7EJkgswuRCbI7EJkgswuRCbI7EJkgswuRCbI7EJkQsnz7GwUbpT73LFjR1KLcq4sRw8AAwcOpPo3v/nNpBblyaM21lHO9uTJk1RnY5ej/QOTJ0+melRbHR1/27ZtSW3ixIk0lrVbBnhdNwDce++9Se23v/0tjR0yZAjVo/0F+/fvp/rZZ5+d1NauXUtj2YjvHj3Sz996ZhciE2R2ITJBZhciE2R2ITJBZhciE2R2ITJBZhciE0qaZz916hQOHz6c1N98800af+utqYGy8fjelpYWqv/tb3+j+s0335zUdu7cSWPXrVtH9TFjxlD9ggsuoPpVV12V1Fi/ewB46KGHqH7XXXdRPRpdzM778uXLaewPf/hDqkc98V944YWk9sYbb9DY6JyzPR8A0L9/f6ovW7YsqbHHOcBz6az3QfjMbmYPm1mzma0647r7zGy7mTUUvm6IjiOEKC/teRn/CIDr27j+Z+4+qfD1XOcuSwjR2YRmd/elAPaUYC1CiC6kmA/ovm1mbxZe5ic3SJvZbDOrN7N61h9LCNG1dNTscwCMATAJQBOAn6R+0d3nunutu9f27t27gzcnhCiWDpnd3Xe6+0l3PwXgVwB4m1AhRNnpkNnN7MzZyl8CkO7ZK4ToFoTz2c3sCQDTAFQD2AngB4WfJwFwAJsBfMPd00XVBaqrq/3GG29M6lFd+IYNG5JalEf/9Kc/TfXVq1dTfeTIkUmN1RcDPN8LABUVFVRvbm6mel1dXVKLZsOPGzeO6lEe/uKLL6b6nj3pz3ZrampobDS//aKLLqI6m5G+ceNGGhvNIWDnHABaW1upzurZ582bR2PHjx+f1F588UXs2bOnzQEM4aYad28rw//rKE4I0b3QdlkhMkFmFyITZHYhMkFmFyITZHYhMqGkJa4VFRU0TcVSJQDQr1+/pNarVy8aG40enjlzJtVPnDiR1J544gka+4UvfIHqrGQRiMcqs5bL0Xn50Y9+RPXa2lqqV1VVUZ2l3kaMGEFjo7/Z5s2bqX7llVcmtX379tHYKGUZlbhGqWCWVrz99ttpLBtFrVbSQgiZXYhckNmFyASZXYhMkNmFyASZXYhMkNmFyISS5tlPnDhB84/R+F+W24xy1RMmTKA6Gy0MAL/85S+TWlSaW2ypZtRymd3+mjVraOw111xD9ei8shHcAC//jVpwb9q0ierXX99WH9T/J8qlM6IR4CtWrKB6NI56+PDhSY21mQb4+HE2SlrP7EJkgswuRCbI7EJkgswuRCbI7EJkgswuRCbI7EJkQthKujOprKz0adOmJfWohnjIkCFJbffu3TSWjbIFgIaGBqpfffXVSS2qGY/GQTc2NlL9tttuozrL2bI6fAD47ne/S/UHHniA6qyWHgAGDhyY1B577DEaG63t73//O9WnTk3PLonae1966aVUP+ecc6i+cOFCqvfp0yepRWPS2H6UZ599Frt27WqzlbSe2YXIBJldiEyQ2YXIBJldiEyQ2YXIBJldiEyQ2YXIhJLm2Wtqavzmm29O6myMLcDrn6P64aVLl1I9ysOzWvrp06fT2C1btlA9qhk/efIk1Vldd5RPjvYIRPXwV1xxBdVfeumlpHbPPffQ2N///vdUP//886l+5MiRpBbtbWAjuoF4T0hTE59gzur8X3vtNRo7bNiwpLZ48WK0trZ2LM9uZiPMbImZrTGz1WZ2d+H6QWa20MzeLVzyzhNCiLLSnpfxJwDc6+7jAFwO4Ftm9ikA3wOw2N3HAlhc+FkI0U0Jze7uTe6+svD9AQBrAAwDcBOARwu/9iiAmV20RiFEJ/AvfUBnZqMATAawDMBgd28CTv9DAFCTiJltZvVmVv/+++8XuVwhREdpt9nNrD+APwL4jrvvb2+cu89191p3r40GFAohuo52md3MeuK00X/n7vMLV+80s6EFfSiA5q5ZohCiMwhbSZuZAfg1gDXu/tMzpAUAZgH4ceHymehYR44cwfr165N6lGJi6Yqo7XA0ejhKQb399ttJbcGCBTT2rLPOonpdXR3Vo9HELI0UlaBGLZPvuOMOqv/5z3+mOrtvixYtorFjxoyh+uHDh6k+ePDgpBalDOfNm0f1iooKqkelxb17905qn/nMZ2js9u3bkxpL47anb3wdgK8CeMvMGgrXfR+nTf6Umd0BYCuAL7fjWEKIMhGa3d1fAdBmkh4AnzAghOg2aLusEJkgswuRCTK7EJkgswuRCTK7EJlQ0pHNvXv3prnT/fv5xjw2HvjQoUPhbTOiVtSrV69OapMnT6axUTnlhg0bqB7tPJwzZ05Si0YyR7nsqDQ42p/A/qaszTQQ7xEYMWIE1aO9F4wDBw5QPcqzR6XBl112WVJrbW2lscwHrEW1ntmFyASZXYhMkNmFyASZXYhMkNmFyASZXYhMkNmFyISS5tkBgLWuZvlDADjvvPOSWjFtqAHedhgAbrjhhqQW5WTZuGcAWLlyJdUvvPBCqu/ZsyepsXUD8djjqLb6ueeeozobffzyyy/T2K997WtUv//++6l+ySWXJLVofwHrnQAATz75JNVvv/12qrPW5Nu2baOxgwYNSmqsJ4Se2YXIBJldiEyQ2YXIBJldiEyQ2YXIBJldiEyQ2YXIhJKObK6urvYbb7wxqUdjct95552k1r9/fxrLem0D8dhk1gf82muvpbFRPnn8+PFUX7hwIdVZbXRUC79v3z6qR3XZlZV8eG+/fv06fNtRj4Go9zvr5x/VwrOe8wAwYcIEqr/++utUZ4+3qPfClClTktqDDz6IxsbGjo1sFkL8eyCzC5EJMrsQmSCzC5EJMrsQmSCzC5EJMrsQmdCe+ewjAPwGwBAApwDMdfcHzew+AHcCaCn86vfdnRY3uzuOHz+e1KNc+OjRo5Ma6+sO8NzkB2tjsLnyBw8epLFXXnkl1aP57ZdffjnV2XlramqisZMmTaL6LbfcQvWhQ4dS/aWXXkpqUY5+xowZVI/2ZTQ0NCS1qF496t0e7V8YMmQI1dmcA9b7HeA16+xx3J7mFScA3OvuK81sAIDXzeyDXR4/c/cH2nEMIUSZac989iYATYXvD5jZGgDDunphQojO5V96z25mowBMBrCscNW3zexNM3vYzNp8TWZms82s3szqjx49WtxqhRAdpt1mN7P+AP4I4Dvuvh/AHABjAEzC6Wf+n7QV5+5z3b3W3WujPb9CiK6jXWY3s544bfTfuft8AHD3ne5+0t1PAfgVgKldt0whRLGEZjczA/BrAGvc/adnXH/mx7BfArCq85cnhOgs2vNpfB2ArwJ4y8waCtd9H8CtZjYJgAPYDOAb0YHMDD179kzqUTto1vZ43LhxNPbYsWNUj95isDbXURvqrVu3Uj1a+1tvvUX1iRMndkgD4jLS5cuXUz06r+y8RS22//CHP1D99PNQmrFjxya16upqGtvS0kL15uZmqrOSaICnkaN0KSv1Zo/F9nwa/wqAts4qbxguhOhWaAedEJkgswuRCTK7EJkgswuRCTK7EJkgswuRCSVtJV1VVeWf//znk3q0FlaWGOU9WUtjADh16hTVWd40ytGzEbvtIVr7hg0bklpULslytgBQV1dH9ag8l42TjnL0URlqNIabtcGO2n+zMlIAWLt2LdWHDx9O9cbGxqR2+PBhGsv2Dzz11FNobm5WK2khckZmFyITZHYhMkFmFyITZHYhMkFmFyITZHYhMqGkeXYzawGw5YyrqgHsKtkC/jW669q667oAra2jdObaznP3c9oSSmr2j924Wb2715ZtAYTuurbuui5Aa+sopVqbXsYLkQkyuxCZUG6zzy3z7TO669q667oAra2jlGRtZX3PLoQoHeV+ZhdClAiZXYhMKIvZzex6M3vHzNab2ffKsYYUZrbZzN4yswYzqy/zWh42s2YzW3XGdYPMbKGZvVu45HOPS7u2+8xse+HcNZjZDWVa2wgzW2Jma8xstZndXbi+rOeOrKsk563k79nNrALAOgCfBbANwAoAt7r72yVdSAIz2wyg1t3LvgHDzK4CcBDAb9x9QuG6+wHscfcfF/5RVrr7f3WTtd0H4GC5x3gXphUNPXPMOICZAP4TZTx3ZF23oATnrRzP7FMBrHf3je5+DMCTAG4qwzq6Pe6+FMBHW73cBODRwveP4vSDpeQk1tYtcPcmd19Z+P4AgA/GjJf13JF1lYRymH0YgDN78mxD95r37gBeNLPXzWx2uRfTBoPdvQk4/eABUFPm9XyUcIx3KfnImPFuc+46Mv68WMph9rb6Y3Wn/F+du18KYAaAbxVeror20a4x3qWijTHj3YKOjj8vlnKYfRuAEWf8PBzAjjKso03cfUfhshnAn9D9RlHv/GCCbuGSd9osId1pjHdbY8bRDc5dOcefl8PsKwCMNbPRZtYLwFcALCjDOj6GmfUrfHACM+sH4Dp0v1HUCwDMKnw/C8AzZVzLh+guY7xTY8ZR5nNX9vHn7l7yLwA34PQn8hsA/Hc51pBY1/kA3ih8rS732gA8gdMv647j9CuiOwBUAVgM4N3C5aButLbHALwF4E2cNtbQMq3tP3D6reGbABoKXzeU+9yRdZXkvGm7rBCZoB10QmSCzC5EJsjsQmSCzC5EJsjsQmSCzC5EJsjsQmTC/wKLTIRlGMNoIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00010118]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec, G_loss = {}, D_loss = {}'.format(epoch + 1, time.time()-start,gen_loss,disc_loss))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
